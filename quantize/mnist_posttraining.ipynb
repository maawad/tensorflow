{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the examples from:\n",
    "https://www.tensorflow.org/lite/performance/post_training_integer_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets for training and test\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input data\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 12)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2028)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20290     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "from keras.models import Sequential\n",
    "from keras import models, layers\n",
    "from keras import regularizers\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   1/1875 [..............................] - ETA: 4:24 - loss: 2.3360 - accuracy: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 13:46:25.965924: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2668 - accuracy: 0.9250 - val_loss: 0.1239 - val_accuracy: 0.9631\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1131 - accuracy: 0.9672 - val_loss: 0.0946 - val_accuracy: 0.9718\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0854 - accuracy: 0.9754 - val_loss: 0.0732 - val_accuracy: 0.9772\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0712 - accuracy: 0.9787 - val_loss: 0.0734 - val_accuracy: 0.9759\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0621 - accuracy: 0.9815 - val_loss: 0.0712 - val_accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_images, train_labels,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(test_images,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tflite_models(num_quantize_images, representative_data_generator):\n",
    "    # non quantized model\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    fp32_model = converter.convert()\n",
    "\n",
    "    # float16 quantized model\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    fp16_model = converter.convert()\n",
    "\n",
    "    # int8 quantized model\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_generator\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "\n",
    "    int8_model = converter.convert()\n",
    "    return fp32_model, fp16_model, int8_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(model, test_image_indices):\n",
    "  global test_images\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_content=model)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_images[test_image_index]\n",
    "    test_label = test_labels[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(tflite_model, model_type):\n",
    "  global test_images\n",
    "  global test_labels\n",
    "\n",
    "  test_image_indices = range(test_images.shape[0])\n",
    "  predictions = run_tflite_model(tflite_model, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_labels== predictions) * 100) / len(test_images)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpng5si6ur/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 13:46:51.348320: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-09-25 13:46:51.683100: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-09-25 13:46:51.683114: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpia3ykhbq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 13:46:51.683237: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpng5si6ur\n",
      "2022-09-25 13:46:51.683882: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-09-25 13:46:51.683887: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpng5si6ur\n",
      "2022-09-25 13:46:51.686369: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-09-25 13:46:51.712409: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpng5si6ur\n",
      "2022-09-25 13:46:51.721221: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 37986 microseconds.\n",
      "2022-09-25 13:46:51.731794: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "INFO:tensorflow:Assets written to: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpia3ykhbq/assets\n",
      "2022-09-25 13:46:52.072747: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-09-25 13:46:52.072760: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "2022-09-25 13:46:52.072868: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpia3ykhbq\n",
      "2022-09-25 13:46:52.073614: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-09-25 13:46:52.073622: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpia3ykhbq\n",
      "2022-09-25 13:46:52.075993: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-09-25 13:46:52.104234: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpia3ykhbq\n",
      "2022-09-25 13:46:52.113740: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 40867 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpkowul14q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpkowul14q/assets\n",
      "/Users/mawad/miniconda3/envs/jupyter/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-09-25 13:46:52.481172: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-09-25 13:46:52.481191: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-09-25 13:46:52.481280: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpkowul14q\n",
      "2022-09-25 13:46:52.482001: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-09-25 13:46:52.482010: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpkowul14q\n",
      "2022-09-25 13:46:52.484625: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-09-25 13:46:52.511390: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmpkowul14q\n",
      "2022-09-25 13:46:52.520369: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 39088 microseconds.\n",
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n"
     ]
    }
   ],
   "source": [
    "# Calibration data \n",
    "def representative_data_gen_100():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "fp32_model, fp16_model, int8_model = generate_tflite_models(100, representative_data_gen_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 model accuracy is 97.7900% (Number of test samples=10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp16 model accuracy is 97.7900% (Number of test samples=10000)\n",
      "int8 model accuracy is 97.8300% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(fp32_model, model_type=\"fp32\")\n",
    "evaluate_model(fp16_model, model_type=\"fp16\")\n",
    "evaluate_model(int8_model, model_type=\"int8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef9a102553d787bf90fa506c94b3946816aabd69f4d56d72cacf5b4f0e7beb60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
