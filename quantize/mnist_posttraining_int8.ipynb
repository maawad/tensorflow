{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the examples from:\n",
    "https://www.tensorflow.org/lite/performance/post_training_integer_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets for training and test\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input data\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 10\n",
    "# convert class vectors to binary class matrices\n",
    "# train_labels = keras.utils.np_utils.to_categorical(train_labels, num_classes)\n",
    "# ktest_labels = keras.utils.np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import models, layers\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 12)        120       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 12)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2028)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                20290     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "from keras.models import Sequential\n",
    "from keras import models, layers\n",
    "from keras import regularizers\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  22/1875 [..............................] - ETA: 4s - loss: 2.0507 - accuracy: 0.4034  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 17:34:55.210315: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2730 - accuracy: 0.9241 - val_loss: 0.1252 - val_accuracy: 0.9632\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1117 - accuracy: 0.9679 - val_loss: 0.0977 - val_accuracy: 0.9702\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0840 - accuracy: 0.9749 - val_loss: 0.0756 - val_accuracy: 0.9764\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0701 - accuracy: 0.9797 - val_loss: 0.0795 - val_accuracy: 0.9754\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0608 - accuracy: 0.9821 - val_loss: 0.0645 - val_accuracy: 0.9792\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_images, train_labels,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(test_images,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration data \n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "    yield [input_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmp4gufw3pz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 17:35:21.810286: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-09-24 17:35:22.090524: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-09-24 17:35:22.090543: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "2022-09-24 17:35:22.090680: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmp4gufw3pz\n",
      "2022-09-24 17:35:22.091422: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-09-24 17:35:22.091428: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmp4gufw3pz\n",
      "2022-09-24 17:35:22.094088: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-09-24 17:35:22.120467: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmp4gufw3pz\n",
      "2022-09-24 17:35:22.129694: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 39014 microseconds.\n",
      "2022-09-24 17:35:22.140438: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# non quantized model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmp_3bo8af6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmp_3bo8af6/assets\n",
      "/Users/mawad/miniconda3/envs/jupyter/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-09-24 17:35:22.561108: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-09-24 17:35:22.561123: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-09-24 17:35:22.561211: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmp_3bo8af6\n",
      "2022-09-24 17:35:22.561903: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-09-24 17:35:22.561909: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmp_3bo8af6\n",
      "2022-09-24 17:35:22.564350: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-09-24 17:35:22.590660: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/y7/lgb6jsgs7y5_xp5pqnhc09k80000gn/T/tmp_3bo8af6\n",
      "2022-09-24 17:35:22.600445: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 39234 microseconds.\n",
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n"
     ]
    }
   ],
   "source": [
    "# Quantize the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(model, test_image_indices):\n",
    "  global test_images\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_content=model)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_images[test_image_index]\n",
    "    test_label = test_labels[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale input data to uint8\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Change this to test a different image\n",
    "test_image_index = 1\n",
    "\n",
    "## Helper function to test the models on one image\n",
    "def test_model(tflite_model, test_image_index, model_type):\n",
    "  global test_labels\n",
    "\n",
    "  predictions = run_tflite_model(tflite_model, [test_image_index])\n",
    "\n",
    "  plt.imshow(test_images[test_image_index])\n",
    "  template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n",
    "  _ = plt.title(template.format(true= str(test_labels[test_image_index]), predict=str(predictions[0])))\n",
    "  plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Initialized TensorFlow Lite runtime.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model(tflite_model_quant, test_image_index, model_type=\"Float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_model(tflite_model, test_image_index, model_type=\"Float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(tflite_model, model_type):\n",
    "  global test_images\n",
    "  global test_labels\n",
    "\n",
    "  test_image_indices = range(test_images.shape[0])\n",
    "  predictions = run_tflite_model(tflite_model, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_labels== predictions) * 100) / len(test_images)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model accuracy is 97.9200% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model, model_type=\"Float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model accuracy is 97.8700% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_quant, model_type=\"Quantized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef9a102553d787bf90fa506c94b3946816aabd69f4d56d72cacf5b4f0e7beb60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
